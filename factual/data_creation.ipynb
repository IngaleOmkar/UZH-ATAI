{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from rdflib import Graph\n",
    "import requests\n",
    "from typing import Union, Dict, List\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Graph()\n",
    "g.parse(\"14_graph.nt\", format=\"turtle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'http://www.wikidata.org/entity/Q850522': 'Little Women', 'http://www.wikidata.org/entity/Q4717778': 'Alex Shaffer'}\n"
     ]
    }
   ],
   "source": [
    "def extract_wikidata_id(uri: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract Wikidata ID (Q or P number) from a URI or direct ID string.\n",
    "    \n",
    "    Args:\n",
    "        uri (str): Wikidata URI or ID (e.g., 'http://www.wikidata.org/entity/Q42', \n",
    "                  'http://www.wikidata.org/prop/direct/P495', 'Q42', or 'P495')\n",
    "    \n",
    "    Returns:\n",
    "        str: The extracted Wikidata ID\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If the URI doesn't contain a valid Wikidata ID\n",
    "    \"\"\"\n",
    "    # Check if it's already just a Q/P number\n",
    "    if re.match(r'^[QP]\\d+$', uri):\n",
    "        return uri\n",
    "    \n",
    "    # Extract from URI\n",
    "    match = re.search(r'[QP]\\d+', uri)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    \n",
    "    raise ValueError(f\"Invalid Wikidata identifier: {uri}\")\n",
    "\n",
    "def get_wikidata_label(uri: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert a Wikidata URI to human readable text by querying the Wikidata API.\n",
    "    Works for both entities (Q) and properties (P).\n",
    "    \n",
    "    Args:\n",
    "        uri (str): Wikidata URI or ID (e.g., 'http://www.wikidata.org/entity/Q42', \n",
    "                  'http://www.wikidata.org/prop/direct/P495', 'Q42', or 'P495')\n",
    "        \n",
    "    Returns:\n",
    "        str: Human readable label for the entity or property\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If the URI is invalid\n",
    "        RequestException: If the API request fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        entity_id = extract_wikidata_id(uri)\n",
    "    except ValueError as e:\n",
    "        return str(e)\n",
    "    \n",
    "    # Determine if it's a property or entity\n",
    "    is_property = entity_id.startswith('P')\n",
    "    \n",
    "    # Construct the API URL\n",
    "    api_url = 'https://www.wikidata.org/w/api.php'\n",
    "    \n",
    "    if is_property:\n",
    "        # For properties, we need to use the wbgetentities API with different parameters\n",
    "        params = {\n",
    "            'action': 'wbgetentities',\n",
    "            'ids': entity_id,\n",
    "            'format': 'json',\n",
    "            'props': 'labels|datatype',  # Include datatype for properties\n",
    "            'languages': 'en'\n",
    "        }\n",
    "    else:\n",
    "        # For regular entities\n",
    "        params = {\n",
    "            'action': 'wbgetentities',\n",
    "            'ids': entity_id,\n",
    "            'format': 'json',\n",
    "            'props': 'labels',\n",
    "            'languages': 'en'\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(api_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        # Check if entity/property exists\n",
    "        if 'entities' not in data or entity_id not in data['entities']:\n",
    "            return f\"ID {entity_id} not found\"\n",
    "            \n",
    "        # Get English label if available\n",
    "        entity = data['entities'][entity_id]\n",
    "        label = None\n",
    "        \n",
    "        if 'labels' in entity and 'en' in entity['labels']:\n",
    "            label = entity['labels']['en']['value']\n",
    "            \n",
    "            # For properties, append the datatype if available\n",
    "            if is_property and 'datatype' in entity:\n",
    "                label = f\"{label} ({entity['datatype']})\"\n",
    "                \n",
    "            return label\n",
    "        else:\n",
    "            return f\"No English label found for {entity_id}\"\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise requests.exceptions.RequestException(f\"Failed to fetch data: {str(e)}\")\n",
    "\n",
    "def batch_convert_uris(uris: List[str]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Convert multiple Wikidata URIs to human readable text in a single batch request.\n",
    "    Works for both entities (Q) and properties (P).\n",
    "    \n",
    "    Args:\n",
    "        uris (List[str]): List of Wikidata URIs or IDs\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, str]: Dictionary mapping URIs to their human readable labels\n",
    "    \"\"\"\n",
    "    # Extract IDs and create a mapping\n",
    "    id_mapping = {}\n",
    "    q_ids = []\n",
    "    p_ids = []\n",
    "    \n",
    "    for uri in uris:\n",
    "        try:\n",
    "            wikidata_id = extract_wikidata_id(uri)\n",
    "            id_mapping[uri] = wikidata_id\n",
    "            \n",
    "            if wikidata_id.startswith('Q'):\n",
    "                q_ids.append(wikidata_id)\n",
    "            else:  # P ids\n",
    "                p_ids.append(wikidata_id)\n",
    "        except ValueError as e:\n",
    "            id_mapping[uri] = str(e)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Process both Q and P IDs in separate batches\n",
    "    for id_list in [q_ids, p_ids]:\n",
    "        if not id_list:\n",
    "            continue\n",
    "            \n",
    "        # Process in batches of 50\n",
    "        for i in range(0, len(id_list), 50):\n",
    "            batch = id_list[i:i + 50]\n",
    "            \n",
    "            api_url = 'https://www.wikidata.org/w/api.php'\n",
    "            params = {\n",
    "                'action': 'wbgetentities',\n",
    "                'ids': '|'.join(batch),\n",
    "                'format': 'json',\n",
    "                'props': 'labels|datatype',  # Include datatype for properties\n",
    "                'languages': 'en'\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                response = requests.get(api_url, params=params)\n",
    "                response.raise_for_status()\n",
    "                data = response.json()\n",
    "                \n",
    "                for wikidata_id, entity_data in data['entities'].items():\n",
    "                    if 'labels' in entity_data and 'en' in entity_data['labels']:\n",
    "                        label = entity_data['labels']['en']['value']\n",
    "                        \n",
    "                        # Add datatype for properties\n",
    "                        if wikidata_id.startswith('P') and 'datatype' in entity_data:\n",
    "                            label = f\"{label} ({entity_data['datatype']})\"\n",
    "                        \n",
    "                        # Find original URI(s) for this ID\n",
    "                        for uri, mapped_id in id_mapping.items():\n",
    "                            if mapped_id == wikidata_id:\n",
    "                                results[uri] = label\n",
    "                    else:\n",
    "                        # Handle missing labels\n",
    "                        for uri, mapped_id in id_mapping.items():\n",
    "                            if mapped_id == wikidata_id:\n",
    "                                results[uri] = f\"No English label found for {wikidata_id}\"\n",
    "                                \n",
    "            except requests.exceptions.RequestException as e:\n",
    "                # On error, mark all URIs in this batch as failed\n",
    "                for uri, mapped_id in id_mapping.items():\n",
    "                    if mapped_id in batch:\n",
    "                        results[uri] = f\"Failed to fetch: {str(e)}\"\n",
    "    \n",
    "    # Add any URIs that had invalid IDs to the results\n",
    "    for uri, mapped_id in id_mapping.items():\n",
    "        if uri not in results:\n",
    "            results[uri] = mapped_id  # This will contain the error message\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x103928700>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/atai/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "# Initialize dictionaries to store triples\n",
    "subject_predicate_to_object = {}\n",
    "predicate_object_to_subject = {}\n",
    "subject_object_to_predicate = {}\n",
    "\n",
    "uri_to_label = {}\n",
    "label_to_uri = {}\n",
    "\n",
    "# Parse the graph and populate the dictionaries\n",
    "# THis should be able to handle multiple values for the same key\n",
    "for s, p, o in g:\n",
    "    if (s, p) not in subject_predicate_to_object:\n",
    "        subject_predicate_to_object[(s, p)] = []\n",
    "    subject_predicate_to_object[(s, p)].append(o)\n",
    "    if (p, o) not in predicate_object_to_subject:\n",
    "        predicate_object_to_subject[(p, o)] = []\n",
    "    predicate_object_to_subject[(p, o)].append(s)\n",
    "    if (s, o) not in subject_object_to_predicate:\n",
    "        subject_object_to_predicate[(s, o)] = []\n",
    "    subject_object_to_predicate[(s, o)].append(p)\n",
    "\n",
    "    # Convert URIs to human readable labels\n",
    "    uri_to_label[s] = get_wikidata_label(s)\n",
    "    uri_to_label[p] = get_wikidata_label(p)\n",
    "    uri_to_label[o] = get_wikidata_label(o)\n",
    "\n",
    "    # Add reverse mapping\n",
    "    label_to_uri[uri_to_label[s]] = s\n",
    "    label_to_uri[uri_to_label[p]] = p\n",
    "    label_to_uri[uri_to_label[o]] = o\n",
    "\n",
    "\n",
    "# Save the dictionaries to a file\n",
    "with open('triples.pkl', 'wb') as f:\n",
    "    pickle.dump((subject_predicate_to_object, predicate_object_to_subject, subject_object_to_predicate, label_to_uri, uri_to_label), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get object given subject and predicate\n",
    "def get_object(subject, predicate):\n",
    "    return subject_predicate_to_object.get((subject, predicate))\n",
    "\n",
    "# Get subject given predicate and object\n",
    "def get_subject(predicate, obj):\n",
    "    return predicate_object_to_subject.get((predicate, obj))\n",
    "\n",
    "# Get predicate given subject and object\n",
    "def get_predicate(subject, obj):\n",
    "    return subject_object_to_predicate.get((subject, obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
